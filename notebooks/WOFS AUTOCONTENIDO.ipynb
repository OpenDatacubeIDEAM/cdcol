{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datacube\n",
    "from datacube.storage import netcdf_writer\n",
    "from datacube.model import Variable, CRS\n",
    "import os\n",
    "import re\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PAR√ÅMETROS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "time_ranges = [(\"2014-01-01\", \"2014-12-31\")]\n",
    "product = 'LS8_OLI_LEDAPS'\n",
    "execID=\"WOFS-1-EX\"\n",
    "algorithm = \"WOFS\"\n",
    "version= 1\n",
    "min_long = -74\n",
    "min_lat = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consulta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dc = datacube.Datacube(app=\"WOFS-1\")\n",
    "xarr={}\n",
    "i=0\n",
    "for tr in time_ranges:\n",
    "    xarr[i] = dc.load(product=product, longitude=(min_long, min_long+1.0), latitude=(min_lat, min_lat+1), time=tr)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xarr0=xarr[0]\n",
    "del xarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:          (latitude: 3686, longitude: 3705, time: 22)\n",
       "Coordinates:\n",
       "  * time             (time) datetime64[ns] 2014-01-10T15:08:36 ...\n",
       "  * latitude         (latitude) float64 0.9999 0.9996 0.9993 0.9991 0.9988 ...\n",
       "  * longitude        (longitude) float64 -74.0 -74.0 -74.0 -74.0 -74.0 -74.0 ...\n",
       "Data variables:\n",
       "    coastal_aerosol  (time, latitude, longitude) int16 100 101 100 101 100 ...\n",
       "    blue             (time, latitude, longitude) int16 136 134 137 131 136 ...\n",
       "    green            (time, latitude, longitude) int16 301 320 301 300 304 ...\n",
       "    red              (time, latitude, longitude) int16 177 184 176 179 179 ...\n",
       "    nir              (time, latitude, longitude) int16 3066 3235 3068 2989 ...\n",
       "    swir1            (time, latitude, longitude) int16 1503 1451 1415 1365 ...\n",
       "    swir2            (time, latitude, longitude) int16 552 539 529 507 521 ...\n",
       "    cf_mask          (time, latitude, longitude) int16 0 0 0 0 0 0 0 0 0 0 0 ...\n",
       "    cf_mask_conf     (time, latitude, longitude) int16 1 1 1 1 1 1 1 1 1 1 1 ...\n",
       "    cloud            (time, latitude, longitude) int16 32 32 32 32 32 32 32 ...\n",
       "Attributes:\n",
       "    crs: EPSG:4326"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xarr0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algoritmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gc\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def wofs_classify(dataset_in, clean_mask=None, no_data=-9999, enforce_float64=False):\n",
    "    \"\"\"\n",
    "    Description:\n",
    "      Performs WOfS algorithm on given dataset. If no clean mask is given, the 'cf_mask'\n",
    "      variable must be included in the input dataset, as it will be used to create a \n",
    "      clean mask\n",
    "    Assumption:\n",
    "      - The WOfS algorithm is defined for Landsat 5/Landsat 7 \n",
    "    References:\n",
    "      - Mueller, et al. (2015) \"Water observations from space: Mapping surface water from \n",
    "        25 years of Landsat imagery across Australia.\" Remote Sensing of Environment.\n",
    "      - https://github.com/GeoscienceAustralia/eo-tools/blob/stable/eotools/water_classifier.py\n",
    "    -----\n",
    "    Inputs:\n",
    "      dataset_in (xarray.Dataset) - dataset retrieved from the Data Cube; should contain\n",
    "        coordinates: time, latitude, longitude\n",
    "        variables: blue, green, red, nir, swir1, swir2\n",
    "        If user does not provide a clean_mask, dataset_in must also include the cf_mask\n",
    "        variable\n",
    "    Optional Inputs:\n",
    "      clean_mask (nd numpy array with dtype boolean) - true for values user considers clean;\n",
    "        if user does not provide a clean mask, one will be created using cfmask\n",
    "      no_data (int/float) - no data pixel value; default: -9999\n",
    "      enforce_float64 (boolean) - flag to indicate whether or not to enforce float64 calculations;\n",
    "        will use float32 if false\n",
    "    Output:\n",
    "      dataset_out (xarray.DataArray) - wofs water classification results: 0 - not water; 1 - water\n",
    "    \"\"\"\n",
    "    \n",
    "    def _band_ratio(a, b):\n",
    "        \"\"\"\n",
    "        Calculates a normalized ratio index\n",
    "        \"\"\"\n",
    "        return (a - b) / (a + b)\n",
    "        \n",
    "    def _run_regression(band1, band2, band3, band4, band5, band7):\n",
    "        \"\"\"\n",
    "        Regression analysis based on Australia's training data\n",
    "        TODO: Return type\n",
    "        \"\"\"\n",
    "        \n",
    "        # Compute normalized ratio indices\n",
    "        ndi_52 = _band_ratio(band5, band2)\n",
    "        ndi_43 = _band_ratio(band4, band3)\n",
    "        ndi_72 = _band_ratio(band7, band2)\n",
    "        \n",
    "        #classified = np.ones(shape, dtype='uint8')\n",
    "        \n",
    "        classified = np.full(shape, no_data)\n",
    "      \n",
    "        # Start with the tree's left branch, finishing nodes as needed\n",
    "        \n",
    "        # Left branch\n",
    "        r1 = ndi_52 <= -0.01\n",
    "\n",
    "        r2 = band1 <= 2083.5\n",
    "        classified[r1 & ~r2] = 0 #Node 3\n",
    "\n",
    "        r3 = band7 <= 323.5\n",
    "        _tmp = r1 & r2\n",
    "        _tmp2 = _tmp & r3\n",
    "        _tmp &= ~r3\n",
    "\n",
    "        r4 = ndi_43 <= 0.61\n",
    "        classified[_tmp2 & r4] = 1 #Node 6\n",
    "        classified[_tmp2 & ~r4] = 0 #Node 7\n",
    "\n",
    "        r5 = band1 <= 1400.5\n",
    "        _tmp2 = _tmp & ~r5\n",
    "\n",
    "        r6 = ndi_43 <= -0.01\n",
    "        classified[_tmp2 & r6] = 1 #Node 10\n",
    "        classified[_tmp2 & ~r6] = 0 #Node 11\n",
    "\n",
    "        _tmp &= r5\n",
    "\n",
    "        r7 = ndi_72 <= -0.23\n",
    "        _tmp2 = _tmp & ~r7\n",
    "\n",
    "        r8 = band1 <= 379\n",
    "        classified[_tmp2 & r8] = 1 #Node 14\n",
    "        classified[_tmp2 & ~r8] = 0 #Node 15\n",
    "\n",
    "        _tmp &= r7\n",
    "\n",
    "        r9 = ndi_43 <= 0.22\n",
    "        classified[_tmp & r9] = 1 #Node 17\n",
    "        _tmp &= ~r9\n",
    "\n",
    "        r10 = band1 <= 473\n",
    "        classified[_tmp & r10] = 1 #Node 19\n",
    "        classified[_tmp & ~r10] = 0 #Node 20\n",
    "\n",
    "        # Left branch complete; cleanup\n",
    "        del r2, r3, r4, r5, r6, r7, r8, r9, r10\n",
    "        gc.collect()\n",
    "        \n",
    "        # Right branch of regression tree\n",
    "        r1 = ~r1\n",
    "\n",
    "        r11 = ndi_52 <= 0.23\n",
    "        _tmp = r1 & r11\n",
    "\n",
    "        r12 = band1 <= 334.5\n",
    "        _tmp2 = _tmp & ~r12\n",
    "        classified[_tmp2] = 0 #Node 23\n",
    "\n",
    "        _tmp &= r12\n",
    "\n",
    "        r13 = ndi_43 <= 0.54\n",
    "        _tmp2 = _tmp & ~r13\n",
    "        classified[_tmp2] = 0 #Node 25\n",
    "\n",
    "        _tmp &= r13\n",
    "\n",
    "        r14 = ndi_52 <= 0.12\n",
    "        _tmp2 = _tmp & r14\n",
    "        classified[_tmp2] = 1 #Node 27\n",
    "\n",
    "        _tmp &= ~r14\n",
    "\n",
    "        r15 = band3 <= 364.5\n",
    "        _tmp2 = _tmp & r15\n",
    "\n",
    "        r16 = band1 <= 129.5\n",
    "        classified[_tmp2 & r16] = 1 #Node 31\n",
    "        classified[_tmp2 & ~r16] = 0 #Node 32\n",
    "\n",
    "        _tmp &= ~r15\n",
    "\n",
    "        r17 = band1 <= 300.5\n",
    "        _tmp2 = _tmp & ~r17\n",
    "        _tmp &= r17\n",
    "        classified[_tmp] = 1 #Node 33\n",
    "        classified[_tmp2] = 0 #Node 34\n",
    "\n",
    "        _tmp = r1 & ~r11\n",
    "\n",
    "        r18 = ndi_52 <= 0.34\n",
    "        classified[_tmp & ~r18] = 0 #Node 36\n",
    "        _tmp &= r18\n",
    "\n",
    "        r19 = band1 <= 249.5\n",
    "        classified[_tmp & ~r19] = 0 #Node 38\n",
    "        _tmp &= r19\n",
    "\n",
    "        r20 = ndi_43 <= 0.45\n",
    "        classified[_tmp & ~r20] = 0 #Node 40\n",
    "        _tmp &= r20\n",
    "\n",
    "        r21 = band3 <= 364.5\n",
    "        classified[_tmp & ~r21] = 0 #Node 42\n",
    "        _tmp &= r21\n",
    "\n",
    "        r22 = band1 <= 129.5\n",
    "        classified[_tmp & r22] = 1 #Node 44\n",
    "        classified[_tmp & ~r22] = 0 #Node 45\n",
    "\n",
    "        # Completed regression tree\n",
    "        \n",
    "        return classified\n",
    "    \n",
    "    # Extract dataset bands needed for calculations\n",
    "    blue = dataset_in.blue\n",
    "    green = dataset_in.green\n",
    "    red = dataset_in.red\n",
    "    nir = dataset_in.nir\n",
    "    swir1 = dataset_in.swir1\n",
    "    swir2 = dataset_in.swir2\n",
    "    \n",
    "    # Create a clean mask from cfmask if the user does not provide one\n",
    "    if not clean_mask:\n",
    "        cfmask = dataset_in.cf_mask\n",
    "        clean_mask = create_cfmask_clean_mask(cfmask)\n",
    "    \n",
    "    # Enforce float calculations - float64 if user specified, otherwise float32 will do\n",
    "    dtype = blue.values.dtype # This assumes all dataset bands will have\n",
    "                              # the same dtype (should be a reasonable\n",
    "                              # assumption)\n",
    "\n",
    "    if enforce_float64:\n",
    "        if dtype != 'float64':\n",
    "            blue.values = blue.values.astype('float64')\n",
    "            green.values = green.values.astype('float64')\n",
    "            red.values = red.values.astype('float64')\n",
    "            nir.values = nir.values.astype('float64')\n",
    "            swir1.values = swir1.values.astype('float64')\n",
    "            swir2.values = swir2.values.astype('float64')\n",
    "    else:\n",
    "        if dtype == 'float64':\n",
    "            pass\n",
    "        elif dtype != 'float32':\n",
    "            blue.values = blue.values.astype('float32')\n",
    "            green.values = green.values.astype('float32')\n",
    "            red.values = red.values.astype('float32')\n",
    "            nir.values = nir.values.astype('float32')\n",
    "            swir1.values = swir1.values.astype('float32')\n",
    "            swir2.values = swir2.values.astype('float32')\n",
    "    \n",
    "    shape = blue.values.shape\n",
    "    classified = _run_regression(blue.values, green.values, red.values, \n",
    "                                 nir.values, swir1.values, swir2.values)\n",
    "\n",
    "    classified_clean = np.full(classified.shape, no_data)\n",
    "    classified_clean[clean_mask] = classified[clean_mask] # Contains data for clear pixels\n",
    "    \n",
    "    # Create xarray of data\n",
    "    time = dataset_in.time\n",
    "    if hasattr(dataset_in,'latitude'):\n",
    "        latitude = dataset_in.latitude \n",
    "        longitude = dataset_in.longitude \n",
    "    \n",
    "        data_array = xr.DataArray(classified_clean,\n",
    "                              coords=[time, latitude, longitude],\n",
    "                              dims=['time', 'latitude', 'longitude'])\n",
    "    \n",
    "        dataset_out = xr.Dataset({'wofs': data_array},\n",
    "                             coords={'time': time,\n",
    "                                     'latitude': latitude,\n",
    "                                     'longitude': longitude})\n",
    "    else:\n",
    "        y = dataset_in.y \n",
    "        x = dataset_in.x\n",
    "        data_array = xr.DataArray(classified_clean,\n",
    "                              coords=[time, y, x],\n",
    "                              dims=['time', 'y', 'x'])\n",
    "    \n",
    "        dataset_out = xr.Dataset({'wofs': data_array},\n",
    "                             coords={'time': time,\n",
    "                                     'y': y,\n",
    "                                     'x': x})\n",
    "                                     \n",
    "    return dataset_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_cfmask_clean_mask(cfmask):\n",
    "    \"\"\"\n",
    "    Description:\n",
    "      Create a clean mask for clear land/water pixels,\n",
    "      i.e. mask out shadow, snow, cloud, and no data\n",
    "    -----\n",
    "    Input:\n",
    "      cfmask (xarray) - cf_mask from the ledaps products\n",
    "    Output:\n",
    "      clean_mask (boolean numpy array) - clear land/water mask\n",
    "    \"\"\"\n",
    "\n",
    "    #########################\n",
    "    # cfmask values:        #\n",
    "    #   0 - clear           #\n",
    "    #   1 - water           #\n",
    "    #   2 - cloud shadow    #\n",
    "    #   3 - snow            #\n",
    "    #   4 - cloud           #\n",
    "    #   255 - fill          #\n",
    "    #########################\n",
    "\n",
    "    clean_mask = np.reshape(np.in1d(cfmask.values.reshape(-1), [2, 3, 4, 255], invert=True),\n",
    "                            cfmask.values.shape)\n",
    "    return clean_mask\n",
    "\n",
    "def get_spatial_ref(crs):\n",
    "    \"\"\"\n",
    "    Description:\n",
    "      Get the spatial reference of a given crs\n",
    "    -----\n",
    "    Input:\n",
    "      crs (datacube.model.CRS) - Example: CRS('EPSG:4326')\n",
    "    Output:\n",
    "      ref (str) - spatial reference of given crs\n",
    "    \"\"\"\n",
    "\n",
    "    crs_str = str(crs)\n",
    "    epsg_code = int(crs_str.split(':')[1])\n",
    "    ref = osr.SpatialReference()\n",
    "    ref.ImportFromEPSG(epsg_code)\n",
    "    return str(ref)\n",
    "\n",
    "def perform_timeseries_analysis(dataset_in, no_data=-9999):\n",
    "    \"\"\"\n",
    "    Description:\n",
    "\n",
    "    -----\n",
    "    Input:\n",
    "      dataset_in (xarray.DataSet) - dataset with one variable to perform timeseries on\n",
    "    Output:\n",
    "      dataset_out (xarray.DataSet) - dataset containing \n",
    "        variables: normalized_data, total_data, total_clean\n",
    "    \"\"\"\n",
    "    \n",
    "    data_vars = dataset_in.data_vars\n",
    "    key = data_vars.keys()[0]\n",
    "    \n",
    "    data = data_vars[key]\n",
    "\n",
    "    #shape = data.shape[1:]\n",
    "\n",
    "    data_dup = data.copy(deep=True)\n",
    "    data_dup.values = data_dup.values.astype('float')\n",
    "    data_dup.values[data.values == no_data] = 0\n",
    "\n",
    "    processed_data_sum = data_dup.sum('time')\n",
    "    # Masking no data values then converting boolean to int for easy summation\n",
    "    clean_data_raw = np.reshape(np.in1d(data.values.reshape(-1), [no_data], invert=True),\n",
    "                                        data.values.shape).astype(int)\n",
    "    # Create xarray of data\n",
    "    time = data.time\n",
    "\n",
    "    if hasattr(data, \"latitude\"):\n",
    "        latitude = data.latitude\n",
    "        longitude = data.longitude\n",
    "        clean_data = xr.DataArray(clean_data_raw,\n",
    "                              coords=[time, latitude, longitude],\n",
    "                              dims=['time', 'latitude', 'longitude'])\n",
    "    else:\n",
    "        y = data.y\n",
    "        x = data.x\n",
    "        clean_data = xr.DataArray(clean_data_raw,\n",
    "                              coords=[time, y, x],\n",
    "                              dims=['time', 'y', 'x'])\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    clean_data_sum = clean_data.sum('time')\n",
    "\n",
    "    processed_data_normalized = processed_data_sum/clean_data_sum\n",
    "    if hasattr(data, \"latitude\"):\n",
    "        dataset_out = xr.Dataset(collections.OrderedDict([('normalized_data', (['latitude', 'longitude'], processed_data_normalized)),\n",
    "                                                      ('total_data', (['latitude', 'longitude'], processed_data_sum)),\n",
    "                                                      ('total_clean', (['latitude', 'longitude'], clean_data_sum))]),\n",
    "                             coords={'latitude': latitude,\n",
    "                                     'longitude': longitude})\n",
    "    else:\n",
    "        dataset_out = xr.Dataset(collections.OrderedDict([('normalized_data', (['y', 'x'], processed_data_normalized)),\n",
    "                                                      ('total_data', (['y', 'x'], processed_data_sum)),\n",
    "                                                      ('total_clean', (['y', 'x'], clean_data_sum))]),\n",
    "                             coords={'y': y,\n",
    "                                     'x': x})\n",
    "    return dataset_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/developer/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:34: RuntimeWarning: invalid value encountered in divide\n",
      "/home/developer/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:34: RuntimeWarning: divide by zero encountered in divide\n",
      "/home/developer/anaconda2/lib/python2.7/site-packages/numpy/core/numeric.py:301: FutureWarning: in the future, full((22, 3686, 3705), -9999) will return an array of dtype('int64')\n",
      "  format(shape, fill_value, array(fill_value).dtype), FutureWarning)\n",
      "/home/developer/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:54: RuntimeWarning: invalid value encountered in less_equal\n",
      "/home/developer/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:64: RuntimeWarning: invalid value encountered in less_equal\n",
      "/home/developer/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:71: RuntimeWarning: invalid value encountered in less_equal\n",
      "/home/developer/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:77: RuntimeWarning: invalid value encountered in less_equal\n",
      "/home/developer/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:86: RuntimeWarning: invalid value encountered in less_equal\n",
      "/home/developer/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:101: RuntimeWarning: invalid value encountered in less_equal\n",
      "/home/developer/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:110: RuntimeWarning: invalid value encountered in less_equal\n",
      "/home/developer/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:116: RuntimeWarning: invalid value encountered in less_equal\n",
      "/home/developer/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:139: RuntimeWarning: invalid value encountered in less_equal\n",
      "/home/developer/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:147: RuntimeWarning: invalid value encountered in less_equal\n"
     ]
    }
   ],
   "source": [
    "output = wofs_classify(xarr0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/developer/anaconda2/lib/python2.7/site-packages/xarray-0.8.2-py2.7.egg/xarray/core/variable.py:1046: RuntimeWarning: invalid value encountered in divide\n",
      "  if not reflexive\n"
     ]
    }
   ],
   "source": [
    "time_series = perform_timeseries_analysis(output)\n",
    "output.attrs[\"crs\"]=xarr0.crs\n",
    "outputs={}\n",
    "outputs[\"normalizado\"] = time_series.normalized_data\n",
    "outputs[\"total_clean\"] = time_series.total_clean\n",
    "outputs[\"total_data\"] = time_series.total_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SALIDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Para dejarlo igual a como lo recibe la tarea gen√©rica\n",
    "kwargs={}\n",
    "kwargs[\"outputs\"]=outputs\n",
    "kwargs[\"output\"]=output\n",
    "folder=\"./\"\n",
    "fns=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:    (latitude: 3686, longitude: 3705, time: 22)\n",
       "Coordinates:\n",
       "  * time       (time) datetime64[ns] 2014-01-10T15:08:36 2014-01-26T15:08:28 ...\n",
       "  * latitude   (latitude) float64 0.9999 0.9996 0.9993 0.9991 0.9988 0.9985 ...\n",
       "  * longitude  (longitude) float64 -74.0 -74.0 -74.0 -74.0 -74.0 -74.0 -74.0 ...\n",
       "Data variables:\n",
       "    wofs       (time, latitude, longitude) float64 0.0 0.0 0.0 0.0 0.0 0.0 ...\n",
       "Attributes:\n",
       "    crs: EPSG:4326"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def saveNC(output,filename):\n",
    "    nodata=9999.\n",
    "    nco=netcdf_writer.create_netcdf(filename)\n",
    "    output=  kwargs[\"output\"]\n",
    "    coords=output.coords\n",
    "    cnames=()\n",
    "    for x in coords:\n",
    "        netcdf_writer.create_coordinate(nco, x, coords[x].values, coords[x].units)\n",
    "        cnames=cnames+(x,)\n",
    "    netcdf_writer.create_grid_mapping_variable(nco, output.crs)\n",
    "    for band in output.data_vars:\n",
    "        output.data_vars[band].values[np.isnan(output.data_vars[band].values)]=nodata\n",
    "        var= netcdf_writer.create_variable(nco, band, Variable(output.data_vars[band].dtype, nodata, cnames, None) ,set_crs=True)\n",
    "        var[:] = netcdf_writer.netcdfy_data(output.data_vars[band].values)\n",
    "    nco.close()\n",
    "if \"output\" in kwargs: #output deber√≠a ser un xarray\n",
    "    #Guardar a un archivo...\n",
    "    filename=folder+\"{}_{}_{}_{}_{}_output.nc\".format(algorithm,str(version),min_lat,min_long,re.sub('[^\\w_.)(-]', '', str(time_ranges)))\n",
    "    output=  kwargs[\"output\"]\n",
    "    saveNC(output,filename)\n",
    "    fns.append(filename)\n",
    "if \"outputs\" in kwargs:\n",
    "    for xa in kwargs[\"outputs\"]:\n",
    "        filename=folder+\"{}_{}_{}_{}_{}_{}.nc\".format(algorithm,str(version),min_lat,min_long,re.sub('[^\\w_.)(-]', '', str(time_ranges)),xa)\n",
    "        saveNC(kwargs[\"outputs\"][xa],filename)\n",
    "        fns.append(filename)\n",
    "if \"outputtxt\" in kwargs:\n",
    "    filename=folder+\"{}_{}_{}.txt\".format(min_lat,min_long,re.sub('[^\\w_.)(-]', '', str(time_ranges)))\n",
    "    with open(filename, \"w\") as text_file:\n",
    "        text_file.write(kwargs[\"outputtxt\"])\n",
    "    fns.append(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
